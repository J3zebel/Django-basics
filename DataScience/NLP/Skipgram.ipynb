{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e04fcbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ff72a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\n",
    "    'Sentence segmentation is the problem of dividing a string',\n",
    "    'of written language into its component sentences. In',\n",
    "    'English and some other languages, using punctuation',\n",
    "   ' particularly the full stop/period character is a reasonable',\n",
    "   ' approximation. However even in English this problem is not trivial',\n",
    "    'due to the use of the full stop character for abbreviations',\n",
    "    'which may or may not also terminate a sentence. For example',\n",
    "    'Mr. is not its own sentence in Mr.Smith went to the shops',\n",
    "    'in Jones Street.When processing plain text, tables of abbreviations',\n",
    "    'that contain periods can help prevent incorrect assignment of sentence boundaries.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5762c92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Sentence',\n",
       "  'segmentation',\n",
       "  'is',\n",
       "  'the',\n",
       "  'problem',\n",
       "  'of',\n",
       "  'dividing',\n",
       "  'a',\n",
       "  'string'],\n",
       " ['of', 'written', 'language', 'into', 'its', 'component', 'sentences.', 'In'],\n",
       " ['English', 'and', 'some', 'other', 'languages,', 'using', 'punctuation'],\n",
       " ['particularly',\n",
       "  'the',\n",
       "  'full',\n",
       "  'stop/period',\n",
       "  'character',\n",
       "  'is',\n",
       "  'a',\n",
       "  'reasonable'],\n",
       " ['approximation.',\n",
       "  'However',\n",
       "  'even',\n",
       "  'in',\n",
       "  'English',\n",
       "  'this',\n",
       "  'problem',\n",
       "  'is',\n",
       "  'not',\n",
       "  'trivial'],\n",
       " ['due',\n",
       "  'to',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'the',\n",
       "  'full',\n",
       "  'stop',\n",
       "  'character',\n",
       "  'for',\n",
       "  'abbreviations'],\n",
       " ['which',\n",
       "  'may',\n",
       "  'or',\n",
       "  'may',\n",
       "  'not',\n",
       "  'also',\n",
       "  'terminate',\n",
       "  'a',\n",
       "  'sentence.',\n",
       "  'For',\n",
       "  'example'],\n",
       " ['Mr.',\n",
       "  'is',\n",
       "  'not',\n",
       "  'its',\n",
       "  'own',\n",
       "  'sentence',\n",
       "  'in',\n",
       "  'Mr.Smith',\n",
       "  'went',\n",
       "  'to',\n",
       "  'the',\n",
       "  'shops'],\n",
       " ['in',\n",
       "  'Jones',\n",
       "  'Street.When',\n",
       "  'processing',\n",
       "  'plain',\n",
       "  'text,',\n",
       "  'tables',\n",
       "  'of',\n",
       "  'abbreviations'],\n",
       " ['that',\n",
       "  'contain',\n",
       "  'periods',\n",
       "  'can',\n",
       "  'help',\n",
       "  'prevent',\n",
       "  'incorrect',\n",
       "  'assignment',\n",
       "  'of',\n",
       "  'sentence',\n",
       "  'boundaries.']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [sentence.split() for sentence in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35a9a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(\n",
    "    sentences,\n",
    "    vector_size=100,\n",
    "    window=4,\n",
    "    min_count=1,\n",
    "    sg=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94d76af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sentence.', 0.24888840317726135), ('Mr.Smith', 0.2387300431728363), ('in', 0.15196414291858673), ('periods', 0.148610919713974), ('string', 0.12842422723770142), ('character', 0.12754739820957184), ('or', 0.12144052982330322), ('that', 0.11475317180156708), ('stop', 0.11446358263492584), ('other', 0.11309481412172318)]\n"
     ]
    }
   ],
   "source": [
    "similar_words = model.wv.most_similar(\"English\")\n",
    "print(similar_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf791035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.9701465e-03 -5.2328939e-03  9.4603356e-03 -9.3011325e-03\n",
      "  4.5268498e-03  5.3930022e-03 -1.3567647e-03  9.0535413e-03\n",
      "  9.8285964e-03 -5.5302680e-03 -6.0302070e-03 -6.8175336e-03\n",
      " -7.9298010e-03 -3.0483240e-03 -5.5551180e-03 -8.3792172e-03\n",
      "  7.9358718e-04  3.0078029e-03  6.3947593e-03 -2.6727971e-03\n",
      " -4.4473894e-03  1.2443708e-03  4.4501232e-04  8.1061637e-03\n",
      "  1.6656621e-04  7.2299954e-03 -8.3174882e-03  8.4186336e-03\n",
      " -1.9223435e-03  8.7004779e-03 -7.6081227e-03  1.7761085e-03\n",
      "  1.0828234e-03 -3.3694461e-05 -5.1279794e-03 -9.2593832e-03\n",
      " -7.2505670e-03 -7.9112155e-03  1.9196948e-03  4.7353946e-04\n",
      " -1.7872801e-03  7.1175718e-03 -2.4680328e-03 -1.3268901e-03\n",
      " -8.8970270e-03 -9.9338861e-03  8.9642210e-03 -5.7808277e-03\n",
      " -6.3669761e-03  5.2322838e-03  6.6772117e-03 -6.8764738e-03\n",
      "  9.7392610e-04 -6.0589486e-03  1.6660148e-03 -4.3346724e-03\n",
      " -3.4150241e-03  2.2299869e-03  8.6376052e-03  6.7630345e-03\n",
      " -9.6895015e-03 -5.6357062e-03  7.9184407e-03  1.9932888e-03\n",
      " -4.2744745e-03  6.2604237e-04  9.5394272e-03 -1.0776952e-03\n",
      " -9.4919596e-03  1.6463479e-03  6.2139863e-03  6.3109030e-03\n",
      "  4.1729198e-03 -5.6517720e-03 -3.2600656e-04 -6.6291163e-05\n",
      "  4.5449445e-03 -8.0324681e-03 -8.0257384e-03  2.1893629e-04\n",
      " -8.6517697e-03  5.8176471e-03 -4.6457181e-04  9.9952072e-03\n",
      " -5.3856089e-03 -5.0403934e-04  7.7968999e-03 -4.0774373e-03\n",
      " -4.9952650e-03  1.5863972e-03  2.6819664e-03 -2.5519405e-03\n",
      "  6.4698644e-03 -7.6738894e-03  3.4474349e-03  4.9078028e-04\n",
      "  8.7435627e-03  5.9922859e-03  6.8277949e-03  7.8030820e-03]\n"
     ]
    }
   ],
   "source": [
    "vector = model.wv[\"English\"]\n",
    "print(vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
